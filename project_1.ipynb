{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 \n",
    " \n",
    " ## Write a Data Science Blog Post\n",
    " \n",
    " This project is in completion of the Udacity Data science NanoDegree lesson 1. \n",
    "\n",
    "Data used for this project are downloaded from https://www.kaggle.com/airbnb/ for both Boston in Massachusetts, and Seattle in Washington State. According to wikipedia \"Seattle is the largest city in both the state of Washington and the Pacific Northwest region of North America\" and boston is the \"most populous city of the Commonwealth of Massachusetts.., and the 21st most populous city in the United States\". This project, using the airbnb data for these two cities, answer questions like : \n",
    " >> 1. What is best property type to list?\n",
    " >> 2. The best cancellation policy to adopt?\n",
    " >> 3. The essential Amenities needed for every listing?\n",
    " >> 4. Predict prices of listing from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the python modules and libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from project_1_func import fill_property, fill_bathrooms, fill_bedrooms_beds, fill_zip\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the boston dataset into dataframes \n",
    "boston_calendar = pd.read_csv('~/Udacity_data_science_/lesson_1_project/boston /calendar.csv')\n",
    "boston_listing = pd.read_csv('~/Udacity_data_science_/lesson_1_project/boston /listings.csv')\n",
    "boston_reviews = pd.read_csv('~/Udacity_data_science_/lesson_1_project/boston /reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the seattle dataset into dataframes \n",
    "seattle_calendar = pd.read_csv('~/Udacity_data_science_/lesson_1_project/seattle /calendar.csv')\n",
    "seattle_listing = pd.read_csv('~/Udacity_data_science_/lesson_1_project/seattle /listings.csv')\n",
    "seattle_reviews = pd.read_csv('~/Udacity_data_science_/lesson_1_project/seattle /reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some exploratory analysis on the boston dataframes \n",
    "boston_calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_calendar.shape # 4 columns and 1308890 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_calendar.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property availabilties\n",
    "boston_calendar.available.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boston review dataframe exploratory data analysis \n",
    "boston_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_reviews.shape # 6 columns and 63275 rows of reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the max review date\n",
    "boston_reviews.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the earliest review date\n",
    "boston_reviews.date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boston listings dataframe anaylysis\n",
    "boston_listing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_listing.shape # 95 columns and 3585 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a copy of the boston listing dataframe \n",
    "\n",
    "boston_listing_copy = boston_listing.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting few columns needed \n",
    "boston_listing_df = boston_listing[['id', 'city', 'state', 'zipcode', 'market', 'country',\n",
    "               'property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'bed_type', 'amenities',\n",
    "                'price', 'neighbourhood_cleansed', 'cancellation_policy', 'guests_included', 'extra_people', 'minimum_nights', 'maximum_nights']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting columns for the analysis \n",
    "# subsetting the dataframe to only market in the Boston area \n",
    "boston_listing_df = boston_listing_df[boston_listing_df.groupby('market')['market'].transform('size') > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_listing_df.shape # 22 columns and 3568 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling rows/columns with null values \n",
    "boston_listing_df.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the columns with Nulls and number of nulls \n",
    "null_columns = boston_listing_df.columns[boston_listing_df.isnull().any()]\n",
    "boston_listing_df[null_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing values on the property type column  \n",
    "boston_listing_df = fill_property(boston_listing_df, 'property_type', 'neighbourhood_cleansed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_listing_df = fill_bathrooms(boston_listing_df, 'bathrooms', 'bedrooms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling na's on bedrooms column\n",
    "boston_listing_df = fill_bedrooms_beds(boston_listing_df, 'bedrooms', 'beds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling na's on bed column\n",
    "boston_listing_df = fill_bedrooms_beds(boston_listing_df, 'beds', 'bedrooms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since Boston is the most stated city value, and the market area is all stated as Boston\n",
    "# fillna in the city column with Boston \n",
    "boston_listing_df['city'].fillna('Boston', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the NaN on the zipcode column \n",
    "# delete this line, use null_replace function\n",
    "boston_listing_df['zipcode'].fillna( boston_listing_df[( boston_listing_df['city'] == 'Boston') & \n",
    "                                                        ( boston_listing_df['neighbourhood_cleansed'] \n",
    "                                                         == 'Roslindale')]\n",
    "                                     ['zipcode'][0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of city values to be replaced \n",
    "city_dict = {'Boston (Jamaica Plain)':'Jamaica Plain', 'dorchester':'Dorchester', 'Boston':'Boston',\n",
    "            'Roslindale':'Roslindale', 'Jamaica plain':'Jamaica Plain', 'Jamaica Plain (Boston)':'Jamaica Plain',\n",
    "            'Boston (Charlestown)' : 'Charlestown', 'South End, Boston':'South End',\n",
    "            'Mission Hill, Boston':'Mission Hill', 'Jamaica Plain (Boston)': 'Jamaica Plain', \n",
    "             'Jamaica Plain, Boston': 'Jamaica Plain', 'Jamaica Plain, MA':'Jamaica Plain'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the city variables with the proper city name\n",
    "for key, value in city_dict.items():\n",
    "    boston_listing_df['city'].replace(key, value, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the row with the japanese character in the city column \n",
    "\n",
    "boston_listing_df = boston_listing_df[boston_listing_df['city'] != '波士顿']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the price column to numeric datatype \n",
    "price_to_str = lambda x: x.strip().replace('$', '').replace(',', '')\n",
    "boston_listing_df['price'] = boston_listing_df['price'].apply(price_to_str) #apply the lambda function  \n",
    "boston_listing_df['price'] = boston_listing_df['price'].apply(pd.to_numeric)  # convert to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_listing_df = boston_listing_df[boston_listing_df.groupby('zipcode')['zipcode'].transform('size') > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_listing_df = fill_zip(boston_listing_df, 'zipcode', 'neighbourhood_cleansed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same process for the seattle listing dataframe \n",
    "seattle_listing.shape # 92 columns and 3818 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting few columns needed \n",
    "seattle_listing_df = seattle_listing[['id', 'city', 'state', 'zipcode', 'market', 'country',\n",
    "               'property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'bed_type', 'amenities',\n",
    "                'price', 'neighbourhood_cleansed', 'cancellation_policy', 'guests_included', 'extra_people', 'minimum_nights', 'maximum_nights']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_listing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_listing_df.market.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value count of the city columns\n",
    "seattle_listing_df.city.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of city values to be replaced \n",
    "city_dict = {'Seattle':'Seattle', 'Phinney Ridge Seattle':'Phinney Ridge', 'Ballard, Seattle':'Ballard', 'seattle':'Seattle'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the city with the proper city name\n",
    "for key, value in city_dict.items():\n",
    "    seattle_listing_df['city'].replace(key, value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the row with the japanese character in the city column \n",
    "\n",
    "seattle_listing_df = seattle_listing_df[seattle_listing_df['city'] != '西雅图']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_listing_df.city.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_listing_df.property_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling rows/columns with null values \n",
    "seattle_listing_df.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the columns with Nulls and number of nulls \n",
    "null_columns = seattle_listing_df.columns[seattle_listing_df.isnull().any()]\n",
    "seattle_listing_df[null_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing values on the property type columns  \n",
    "seattle_listing_df = fill_property(seattle_listing_df, 'property_type', 'neighbourhood_cleansed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling na's on bedrooms column\n",
    "seattle_listing_df = fill_bedrooms_beds(seattle_listing_df, 'bedrooms', 'beds')\n",
    "# filling na's on bed column\n",
    "seattle_listing_df = fill_bedrooms_beds(seattle_listing_df, 'beds', 'bedrooms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_listing_df = fill_bathrooms(seattle_listing_df, 'bathrooms', 'bedrooms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting the seattle_listing_df only to rows where zipcode is NaN\n",
    "df = seattle_listing_df[seattle_listing_df['zipcode'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_listing_df = fill_zip(seattle_listing_df, 'zipcode', 'neighbourhood_cleansed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_to_str = lambda x: x.strip().replace('$', '').replace(',', '')\n",
    "seattle_listing_df['price'] = seattle_listing_df['price'].apply(price_to_str)#apply the lambda function  \n",
    "seattle_listing_df['price'] = seattle_listing_df['price'].apply(pd.to_numeric)  # convert to numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out seattle listings with one listing in an entire zipcode\n",
    "seattle_listing_df = seattle_listing_df[seattle_listing_df.groupby('zipcode')['zipcode'].transform('size') > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a copy of the seattle_listing_df \n",
    "seattle_listing_df_copy = seattle_listing_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amenities to string\n",
    "amenities_to_string = lambda x: str(set(x.split(','))).strip().replace('{', '').replace('}', '').replace('\"', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 1: \n",
    "What is the best property type and numbers of bedrooms to list on Airbnb in Seattle or Boston area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat both dataframe \n",
    "df = [boston_listing_df, seattle_listing_df]\n",
    "listings = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['extra_people'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the column extra people to float\n",
    "listings['extra_people'] = listings['extra_people'].apply(price_to_str) #apply the lambda function  \n",
    "listings['extra_people'] = listings['extra_people'].apply(pd.to_numeric)  # convert to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['amenities'] = listings['amenities'].apply(amenities_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property type distribution in the dataframe \n",
    "listings.property_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting property type with more than 80 listings \n",
    "listings_property = listings[listings.groupby('property_type')['property_type'].transform('size') > 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_property.property_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the plot\n",
    "base_color = sns.color_palette()[0]\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.add_subplot(1, 1, 1)\n",
    "sns.countplot(data = listings_property, x = 'property_type', color = base_color)\n",
    "plt.xlabel('Property Type', fontsize=15)\n",
    "plt.ylabel('Number of Property', fontsize=15)\n",
    "plt.title('Property Type Distribution', fontsize=22)\n",
    "plt.xticks(rotation=15);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value counts for the different bedrooms type\n",
    "listings.bedrooms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting number of bedrooms with more than 50 listings in the dataframe\n",
    "bedroom_listings = listings[listings.groupby('bedrooms')['bedrooms'].transform('size') > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count plot of numbers of bedrooms count \n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.add_subplot(1, 1, 1)\n",
    "sns.countplot(data=bedroom_listings, x='bedrooms')\n",
    "plt.xlabel('Bedrooms', fontsize=15)\n",
    "plt.ylabel('Bedroom count', fontsize=15)\n",
    "plt.title('Bedrooms Distribution', fontsize=25)\n",
    "plt.xticks(rotation=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer:  \n",
    "From the charts above, it is clear that Apartments and 1 bedrooms are the best sellers for Airbnb in the Boston and Seattle area. \n",
    "So anyone looking to start an Airbnb business in these areas should consider listing 1 bedroom apartments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: \n",
    "What is the best cancellation policy to adopt? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the property_types with more than 80 listings\n",
    "listings_property.cancellation_policy.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellation_group = listings_property.cancellation_policy.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# chart of cancellation policies\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.add_subplot(1, 1, 1)\n",
    "(cancellation_group/bedroom_listings.shape[0]).plot(kind=\"bar\");\n",
    "plt.title(\"Cancellation Policies\", fontsize=25);\n",
    "plt.xlabel('Cancellation percentage', fontsize=15)\n",
    "plt.ylabel('Cancellation Type', fontsize=15)\n",
    "plt.xticks(rotation=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancellation policies grouped by number of bedrooms\n",
    "listings_property.groupby(['bedrooms', 'cancellation_policy'])['cancellation_policy'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancellation policies grouped by property_types\n",
    "listings_property.groupby(['property_type', 'cancellation_policy'])['cancellation_policy'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_property.groupby(['room_type', 'cancellation_policy'])['cancellation_policy'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer:\n",
    "From the chart and the distribution above, it is obvious most listers choose the Strict cancellation policies. \n",
    "However, many others prefered either Flexible or Moderate option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3:\n",
    "What are the essential Amenities needed, before listing the property?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast the amenities column as string\n",
    "\n",
    "Amenities_to_str = lambda x: str(set(x.split(','))).strip().replace('{', '').replace('}', '').replace('\"', '').replace('[','').replace(']', '')\n",
    "listings['amenities'] = listings['amenities'].apply(Amenities_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in listings['amenities'][3]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count the occurence of an amenities in the amenities column\n",
    "\n",
    "def total_count(df, col1, col2, look_for):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - the pandas dataframe you want to search\n",
    "    col1 - the column name you want to look through\n",
    "    col2 - the column you want to count values from\n",
    "    look_for - a list of strings you want to search for in each row of df[col]\n",
    "\n",
    "    OUTPUT:\n",
    "    new_df - a dataframe of each look_for with the count of how often it shows up\n",
    "    '''\n",
    "    new_df = defaultdict(int)\n",
    "    #loop through list of ed types\n",
    "    for val in look_for:\n",
    "        #loop through rows\n",
    "        for idx in range(df.shape[0]):\n",
    "            #if the ed type is in the row add 1\n",
    "            if val in df[col1][idx]:\n",
    "                new_df[val] += int(df[col2][idx])\n",
    "    new_df = pd.DataFrame(pd.Series(new_df)).reset_index()\n",
    "    new_df.columns = [col1, col2]\n",
    "    new_df.sort_values('count', ascending=False, inplace=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "possible_amenities = ['Free Parking on Premises', 'Essentials', 'Shampoo', 'Iron', 'Internet', 'Carbon Monoxide Detector', 'Kitchen', 'TV', 'Gym', 'First Aid Kit', 'Laptop Friendly Workspace', \n",
    "    'Wireless Internet', 'Dryer', 'Hair Dryer', 'Air Conditioning','Breakfast','Smoke Detector', 'Safety Card', 'Fire Extinguisher', 'Washer', 'Hangers', 'Heating', 'Indoor Fireplace'\n",
    "   'Fire Extinguisher', 'Smoke Detector', 'Safety Card','Washer', 'Essentials','Internet', 'Heating', 'Dryer', 'Carbon Monoxide Detector', 'Kitchen','Family/Kid Friendly','Indoor Fireplace','Shampoo']\n",
    "\n",
    "def clean_and_plot(df, title='Basic Amenities needed', plot=True):\n",
    "    '''\n",
    "    INPUT \n",
    "        df - a dataframe holding the CousinEducation column\n",
    "        title - string the title of your plot\n",
    "        axis - axis object\n",
    "        plot - bool providing whether or not you want a plot back\n",
    "        \n",
    "    OUTPUT\n",
    "        study_df - a dataframe with the count of how many individuals\n",
    "        Displays a plot of pretty things related to the CousinEducation column.\n",
    "    '''\n",
    "    study = df['amenities'].value_counts().reset_index()\n",
    "    study.rename(columns={'index': 'Amenities Type', 'amenities': 'count'}, inplace=True)\n",
    "    study_df = total_count(study, 'Amenities Type', 'count', possible_amenities)\n",
    "\n",
    "    study_df.set_index('Amenities Type', inplace=True)\n",
    "    if plot:\n",
    "        (study_df/study_df.sum()).plot(kind='bar', legend=None);\n",
    "        plt.title(title);\n",
    "        plt.show()\n",
    "    props_study_df = study_df/study_df.sum()\n",
    "    return props_study_df\n",
    "    \n",
    "props_df = clean_and_plot(seattle_listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer:\n",
    "Every or most of the listings in these market area, either have Internet, \n",
    "Heating and Kitchen. Clearly internet is an essential amenities to have. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4:\n",
    "\n",
    "Predicting price of listings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = listings[[ 'zipcode', 'market',  'property_type',\n",
    "       'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds',\n",
    "       'bed_type', 'neighbourhood_cleansed',\n",
    "       'cancellation_policy', 'guests_included', 'extra_people', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking dtypes of the selected columns \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull a list of the column names of the categorical variables\n",
    "# create dummy variables from categorical columns \n",
    "\n",
    "def create_dummy_df(df, cat_cols, dummy_na):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with categorical variables you want to dummy\n",
    "    cat_cols - list of strings that are associated with names of the categorical columns\n",
    "    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not\n",
    "    \n",
    "    OUTPUT:\n",
    "    df - a new dataframe that has the following characteristics:\n",
    "            1. contains all columns that were not specified as categorical\n",
    "            2. removes all the original columns in cat_cols\n",
    "            3. dummy columns for each of the categorical columns in cat_cols\n",
    "            4. if dummy_na is True - it also contains dummy columns for the NaN values\n",
    "            5. Use a prefix of the column name with an underscore (_) for separating \n",
    "    '''\n",
    "    for col in  cat_cols:\n",
    "        try:\n",
    "            # for each cat add dummy var, drop original column\n",
    "            df = pd.concat([df.drop(col, axis=1), pd.get_dummies(df[col], prefix=col, prefix_sep='_', drop_first=True, dummy_na=dummy_na)], axis=1)\n",
    "        except:\n",
    "            continue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping where the price has missing values\n",
    "df  = df.dropna(subset=['price'], axis=0)\n",
    "\n",
    "#Pull a list of the column names of the categorical variables\n",
    "df_1 = df.select_dtypes(include='object')\n",
    "\n",
    "cat_cols_lst = df_1.columns\n",
    "\n",
    "df_new = create_dummy_df(df, cat_cols_lst, dummy_na=False) #Use your newly created function\n",
    "\n",
    "# Show a header of df_new to check\n",
    "print(df_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the dummy columns are greated\n",
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the dependent and independent variables\n",
    "X = df_new.drop('price', axis=1)\n",
    "y = df_new['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutiple linearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the model to predict listing price\n",
    "y_pred = regressor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model performance using r2 score\n",
    "r2_score(y_test, y_pred) # perform at 57% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
